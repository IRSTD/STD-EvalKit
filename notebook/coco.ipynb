{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'classes': tensor([0, 1], dtype=torch.int32),\n",
      " 'map': tensor(0.),\n",
      " 'map_50': tensor(0.),\n",
      " 'map_75': tensor(0.),\n",
      " 'map_large': tensor(0.),\n",
      " 'map_medium': tensor(-1.),\n",
      " 'map_per_class': tensor(-1.),\n",
      " 'map_small': tensor(-1.),\n",
      " 'mar_1': tensor(0.),\n",
      " 'mar_10': tensor(0.),\n",
      " 'mar_100': tensor(0.),\n",
      " 'mar_100_per_class': tensor(-1.),\n",
      " 'mar_large': tensor(0.),\n",
      " 'mar_medium': tensor(-1.),\n",
      " 'mar_small': tensor(-1.)}\n"
     ]
    }
   ],
   "source": [
    "from torch import tensor\n",
    "from torchmetrics.detection import MeanAveragePrecision\n",
    "from prettytable import PrettyTable\n",
    "import torch\n",
    "from stdeval.metrics import time_cost_deco\n",
    "from stdeval.metrics import BaseMetric, time_cost_deco\n",
    "preds = [\n",
    "   dict(\n",
    "     boxes=tensor([[258.0, 41.0, 606.0, 285.0]]),\n",
    "     scores=tensor([0.536]),\n",
    "     labels=tensor([0]),\n",
    "   )\n",
    " ]\n",
    "target = [\n",
    "   dict(\n",
    "     boxes=tensor([[214.0, 41.0, 562.0, 285.0]]),\n",
    "     labels=tensor([1]),\n",
    "   )\n",
    " ]\n",
    "metric = MeanAveragePrecision(iou_type=\"bbox\")\n",
    "metric.update(preds, target)\n",
    "from pprint import pprint\n",
    "pprint(metric.compute())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from torch import Tensor\n",
    "from typing import List, Dict\n",
    "from stdeval.metrics import time_cost_deco\n",
    "import warnings\n",
    "import pandas as pd\n",
    "class BoxLevelMeanAveragePrecision(MeanAveragePrecision, BaseMetric):\n",
    "    def __init__(self, box_format='xyxy', iou_type=\"bbox\", extended_summary:bool = False, classwise: Dict[int, str]={}, print_table=True, **kwargs):\n",
    "        \"\"\"Compute the Mean-Average-Precision (mAP) and Mean-Average-Recall (mAR) for object detection predictions(COCO).\n",
    "\n",
    "        For ease to use, we encapsulate the MeanAveragePrecision of torchmetrics, \n",
    "        and add some features to make it more user-friendly.\n",
    "        1.We've added metrics and displays for each category.\n",
    "        2.We've added a display of the all metric to ASCII table and DataFrame.\n",
    "        theoretically supports all methods in torchmetrics.detection.mean_ap.MeanAveragePrecision.\n",
    "        \n",
    "        For more information, please refer to the official documentation:\n",
    "        https://lightning.ai/docs/torchmetrics/stable/detection/mean_average_precision.html#torchmetrics.detection.mean_ap.MeanAveragePrecision\n",
    "\n",
    "        Usage:\n",
    "            # For box:\n",
    "                preds = [\n",
    "                dict(\n",
    "                    boxes=tensor([[258.0, 41.0, 606.0, 285.0],\n",
    "                                [158.0, 41.0, 462.0, 285.0]]),\n",
    "                    scores=tensor([0.536, 0.71]),\n",
    "                    labels=tensor([1, 2]),\n",
    "                ),\n",
    "                    dict(\n",
    "                    boxes=tensor([[254.0, 413.0, 656.0, 245.0]]),\n",
    "                    scores=tensor([0.526]),\n",
    "                    labels=tensor([1]),\n",
    "                )\n",
    "                ]\n",
    "                target = [\n",
    "                dict(\n",
    "                    boxes=tensor([[214.0, 41.0, 562.0, 285.0],\n",
    "                                [158.0, 41.0, 462.0, 285.0]]),\n",
    "                    labels=tensor([1,2]),\n",
    "                ),\n",
    "                    dict(\n",
    "                    boxes=tensor([[258.0, 41.0, 606.0, 285.0]]),\n",
    "                    labels=tensor([1]),\n",
    "                )\n",
    "                ]\n",
    "                classwise = {0:'person', 1:'car', 2:'tea', 3:'cycle'} # lbl id 2 name\n",
    "                metric = BoxLevelMetric(iou_type=\"bbox\", class_metrics=True, classwise=classwise)\n",
    "                metric.update(target, preds)\n",
    "                metric.get()\n",
    "                metric.table\n",
    "                metric.reset()\n",
    "\n",
    "\n",
    "            # For mask\n",
    "                mask_pred = [\n",
    "                    [0, 0, 0, 0, 0],\n",
    "                    [0, 0, 1, 1, 0],\n",
    "                    [0, 0, 1, 1, 0],\n",
    "                    [0, 0, 0, 0, 0],\n",
    "                    [0, 0, 0, 0, 0],\n",
    "                    ]\n",
    "                mask_tgt = [\n",
    "                    [0, 0, 0, 0, 0],\n",
    "                    [0, 0, 1, 0, 0],\n",
    "                    [0, 0, 1, 1, 0],\n",
    "                    [0, 0, 1, 0, 0],\n",
    "                    [0, 0, 0, 0, 0],\n",
    "                    ]\n",
    "                preds = [\n",
    "                    dict(\n",
    "                        masks=tensor([mask_pred], dtype=torch.bool),\n",
    "                        scores=tensor([0.536]),\n",
    "                        labels=tensor([0]),\n",
    "                    )\n",
    "                    ]\n",
    "                target = [\n",
    "                    dict(\n",
    "                        masks=tensor([mask_tgt], dtype=torch.bool),\n",
    "                        labels=tensor([0]),\n",
    "                    )\n",
    "                    ]\n",
    "                metric = BoxLevelMeanAveragePrecision(iou_type=\"segm\")\n",
    "                metric.update(target, preds)\n",
    "                metric.get()\n",
    "        \n",
    "        Args:\n",
    "            box_format (str, optional): Params of torchmetrics.detection.MeanAveragePrecision. Defaults to 'xyxy'.\n",
    "            iou_type (str, optional): Params of torchmetrics.detection.MeanAveragePrecision. Defaults to \"bbox\".\n",
    "            extended_summary (bool, optional): Params of torchmetrics.detection.MeanAveragePrecision. Defaults to 'False'. \n",
    "            classwise (Dict[int, str], optional): Methods function to this repo, controls whether use Category name, \\\n",
    "                like classwise = {0:'person', 1:'car', 2:'tea', 3:'cycle'}, label id map to name. Defaults to {}.\n",
    "            print_table (bool, optional): Methods specific to this repo, controls whether an ASCII table to printed. \\\n",
    "                Defaults to True.\n",
    "            **kwargs: Other keyword arguments for torchmetrics.detection.MeanAveragePrecision.\n",
    "        \"\"\"\n",
    "        self.this_extend_summary = extended_summary\n",
    "        self.classwise = classwise\n",
    "\n",
    "        MeanAveragePrecision.__init__(self, iou_type=iou_type, box_format= box_format, extended_summary=True, **kwargs)\n",
    "        BaseMetric.__init__(self, print_table=print_table)\n",
    "        if len(self.iou_type) == 1 :\n",
    "            self.prefix = \"\" \n",
    "        else :\n",
    "            raise ValueError(\"not support iou_type with multiple values\")\n",
    "        \n",
    "        iou_thr = str(round(self.iou_thresholds[0],2)) +':'+ str(round(self.iou_thresholds[-1],2))\n",
    "        self.name2coco = {f'mAP@{iou_thr}' : 'map',\n",
    "                     'mAP@50':f'{self.prefix}map_50',\n",
    "                     'mAP@75':f'{self.prefix}map_75',\n",
    "                     f'mAP_s':f'{self.prefix}map_small',\n",
    "                     f'mAP_m':f'{self.prefix}map_medium',\n",
    "                     f'mAP_l':f'{self.prefix}map_large',\n",
    "                     f'mAR_s':f'{self.prefix}mar_small',\n",
    "                     f'mAR_m':f'{self.prefix}mar_medium',\n",
    "                    f'mAR_l':f'{self.prefix}mar_large',\n",
    "                    f'mAR_max_dets@{self.max_detection_thresholds[0]}':f'{self.prefix}mar_{self.max_detection_thresholds[0]}',\n",
    "                    f'mAR_max_dets@{self.max_detection_thresholds[1]}':f'{self.prefix}mar_{self.max_detection_thresholds[1]}',\n",
    "                   f'mAR_max_dets@{self.max_detection_thresholds[2]}': f'{self.prefix}mar_{self.max_detection_thresholds[2]}',\n",
    "        }\n",
    "\n",
    "    @time_cost_deco\n",
    "    def update(self, labels: List[Dict[str, Tensor]], preds: List[Dict[str, Tensor]]) -> None:\n",
    "        MeanAveragePrecision.update(self,preds, labels)\n",
    "\n",
    "    @time_cost_deco\n",
    "    def get(self) -> dict:\n",
    "        res = MeanAveragePrecision.compute(self)\n",
    "        results_per_category = self._get_per_class_info(res)\n",
    "        results = dict()\n",
    "\n",
    "        if not self.this_extend_summary:\n",
    "            del res[f\"{self.prefix}precision\"]\n",
    "            del res[f\"{self.prefix}recall\"]\n",
    "            del res[f\"{self.prefix}scores\"]\n",
    "            del res[f\"{self.prefix}ious\"]\n",
    "            results['classes'] = res.pop('classes')\n",
    "            results['ALL'] = res\n",
    "            results.update(results_per_category)\n",
    "        else: \n",
    "            results[f\"{self.prefix}precision\"] =res.pop(f\"{self.prefix}precision\")\n",
    "            results[f\"{self.prefix}recall\"] =res.pop(f\"{self.prefix}recall\")\n",
    "            results[f\"{self.prefix}scores\"] =res.pop(f\"{self.prefix}scores\")\n",
    "            results[f\"{self.prefix}ious\"] =res.pop(f\"{self.prefix}ious\")\n",
    "            results['classes'] = res.pop('classes')\n",
    "            results['ALL'] = res\n",
    "            results.update(results_per_category)\n",
    "\n",
    "        self.results = results\n",
    "        if self.print_table:\n",
    "            table = PrettyTable()\n",
    "            head = ['category']\n",
    "            head.extend([k for k,v in self.name2coco.items()])\n",
    "            table.field_names = head\n",
    "            all_row = ['All']\n",
    "            all_row.extend([f\"{self.results['ALL'][v].item():.4f}\" for k, v in self.name2coco.items()])\n",
    "            table.add_row(all_row)\n",
    "            for cls_idx in self.results['classes'].tolist():\n",
    "                row = [self.results[cls_idx]['name']]\n",
    "                row.extend([f\"{self.results[cls_idx][v].item():.4f}\" for k,v in self.name2coco.items()])\n",
    "                table.add_row(row)\n",
    "            print(table)\n",
    "        return self.results\n",
    "    \n",
    "    def reset(self):\n",
    "        self.results = dict()\n",
    "        MeanAveragePrecision.reset(self)\n",
    "\n",
    "    @property\n",
    "    def table(self):\n",
    "        head = ['category']\n",
    "        head.extend([k for k,v in self.name2coco.items()])\n",
    "        all_row = ['All']\n",
    "        data = []\n",
    "        \n",
    "        all_row.extend([f\"{self.results['ALL'][v].item():.4f}\" for k, v in self.name2coco.items()])\n",
    "        data.append(all_row)\n",
    "        for cls_idx in self.results['classes'].tolist():\n",
    "            row = [self.results[cls_idx]['name']]\n",
    "            row.extend([f\"{self.results[cls_idx][v].item():.4f}\" for k,v in self.name2coco.items()])\n",
    "            data.append(row)\n",
    "        df = pd.DataFrame(data).T\n",
    "        df.index = head\n",
    "        return df.T\n",
    "\n",
    "    def __repr__(self) -> str:\n",
    "        return (f'{self.__class__.__name__}(iou_type={self.iou_type}, '\n",
    "                f'box_format={self.box_format}, '\n",
    "                f'iou_threshold={round(self.iou_thresholds[0],2)}:{round(self.iou_thresholds[-1],2)}, '\n",
    "                f'rec_threshold={round(self.rec_thresholds[0],2)}:{round(self.rec_thresholds[-1],2)})'\n",
    "                )\n",
    "    \n",
    "\n",
    "    def _get_per_class_info(self, results:dict):\n",
    "        cat_ids2name = self.classwise\n",
    "        precisions = results['precision']\n",
    "        recalls = results['recall']\n",
    "        classes = results['classes']\n",
    "        iou_thrs = torch.tensor(self.iou_thresholds)\n",
    "        max_dets = self.max_detection_thresholds\n",
    "        # assert len(cat_ids) == precisions.shape[2]\n",
    "        results_per_category = {}\n",
    "        num_iou_thr, num_cls, num_area_rng, num_max_dets = recalls.shape\n",
    "\n",
    "        num_iou_thr, num_rec_thr, num_cls, num_area_rng, num_max_dets = precisions.shape\n",
    "\n",
    "        if len(cat_ids2name)!=0:\n",
    "            for idx, cls_name in cat_ids2name.items():\n",
    "                if not sum(classes[classes==idx]):\n",
    "                    warnings.warn(f\"Category '{cls_name}', ID = {idx} not in preds or targets, but in classwise.\" \n",
    "                          f\"This information can be ignored if you are sure there is not a problem.\")\n",
    "\n",
    "\n",
    "        for idx, cls in enumerate(classes):\n",
    "            cls = cls.item()\n",
    "            if len(cat_ids2name)!=0:\n",
    "                assert cls in cat_ids2name.keys(), f\"labels not in catIds2name, {cls} not in {cat_ids2name.keys()}\"\n",
    "                cat_name = str(cat_ids2name[cls])\n",
    "            else:\n",
    "                cat_name = str(cls)\n",
    "\n",
    "            t = dict(name=cat_name)\n",
    "            # area range index 0: all area ranges\n",
    "            # max dets index -1: typically 100 per image\n",
    "            precision = precisions[:, :, idx, 0, -1]\n",
    "            precision = precision[precision > -1]\n",
    "            if precision.numel():\n",
    "                ap = torch.mean(precision)\n",
    "            else:\n",
    "                ap = torch.tensor([-1])\n",
    "            t[f\"{self.prefix}map\"] = ap\n",
    "\n",
    "            # get .5,, .75.\n",
    "            iou_idx = [torch.where(iou_thrs==iou)[0] for iou in [0.5, 0.75]]\n",
    "            ap = []\n",
    "            for iou, iou_t, in zip(iou_idx, [0.5, 0.75]):\n",
    "                precision = precisions[iou, :, idx, 0, -1]\n",
    "                precision = precision[precision > -1]\n",
    "                if precision.numel():\n",
    "                    ap.append(torch.mean(precision))\n",
    "                else:\n",
    "                    ap.append(torch.tensor([-1]))\n",
    "\n",
    "            t[f\"{self.prefix}map_50\"] = ap[0]\n",
    "            t[f\"{self.prefix}map_75\"] = ap[1]\n",
    "            \n",
    "            # get small, medium, large\n",
    "            ap = [] \n",
    "            for area in range(1, num_area_rng): # 1,2,3; 0 is all area\n",
    "                precision = precisions[:, :, idx, area, -1]\n",
    "                precision = precision[precision > -1]\n",
    "                if precision.numel():\n",
    "                    ap.append(torch.mean(precision))\n",
    "                else:\n",
    "                    ap.append(torch.tensor([-1]))\n",
    "\n",
    "            t[f\"{self.prefix}map_small\"] = ap[0]\n",
    "            t[f\"{self.prefix}map_medium\"] = ap[1]\n",
    "            t[f\"{self.prefix}map_large\"] = ap[2]\n",
    "\n",
    "            # mAR\n",
    "            recall = recalls[:, idx, 0, -1]\n",
    "            recall = recall[recall > -1]\n",
    "            if recall.numel():\n",
    "                ar = torch.mean(recall)\n",
    "            else:\n",
    "                ar = torch.tensor([-1])\n",
    "            t[f\"{self.prefix}mar\"] = ar\n",
    "\n",
    "            # small medium large\n",
    "            ar = []\n",
    "            for area in range(1, num_area_rng): # 1,2,3; 0 is all area\n",
    "                recall = recalls[:, idx, area, -1]\n",
    "                recall = recall[recall > -1]\n",
    "                if recall.numel():\n",
    "                    ar.append(torch.mean(recall))\n",
    "                else:\n",
    "                    ar.append(torch.tensor([-1]))\n",
    "            t[f\"{self.prefix}mar_small\"] = ar[0]\n",
    "            t[f\"{self.prefix}mar_medium\"] = ar[1]\n",
    "            t[f\"{self.prefix}mar_large\"] = ar[2]\n",
    "\n",
    "\n",
    "            for jdx, max_det in enumerate(max_dets): # 1,2,3; 0 is all area\n",
    "                recall = recalls[:, idx, 0, jdx]\n",
    "                recall = recall[recall > -1]\n",
    "                if recall.numel():\n",
    "                    ar=torch.mean(recall)\n",
    "                else:\n",
    "                    ar=torch.tensor([-1])\n",
    "                t[f\"{self.prefix}mar_{max_det}\"] = ar\n",
    "\n",
    "            results_per_category[cls] = t\n",
    "        return results_per_category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BoxLevelMeanAveragePrecision.update() took 0.00s each time.\n",
      "+----------+--------------+--------+--------+---------+---------+--------+---------+---------+--------+----------------+-----------------+------------------+\n",
      "| category | mAP@0.5:0.95 | mAP@50 | mAP@75 |  mAP_s  |  mAP_m  | mAP_l  |  mAR_s  |  mAR_m  | mAR_l  | mAR_max_dets@1 | mAR_max_dets@10 | mAR_max_dets@100 |\n",
      "+----------+--------------+--------+--------+---------+---------+--------+---------+---------+--------+----------------+-----------------+------------------+\n",
      "|   All    |    0.6515    | 0.7525 | 0.7525 | -1.0000 | -1.0000 | 0.6515 | -1.0000 | -1.0000 | 0.6500 |     0.6500     |      0.6500     |      0.6500      |\n",
      "|   car    |    0.3030    | 0.5050 | 0.5050 | -1.0000 | -1.0000 | 0.3030 | -1.0000 | -1.0000 | 0.3000 |     0.3000     |      0.3000     |      0.3000      |\n",
      "|   tea    |    1.0000    | 1.0000 | 1.0000 | -1.0000 | -1.0000 | 1.0000 | -1.0000 | -1.0000 | 1.0000 |     1.0000     |      1.0000     |      1.0000      |\n",
      "+----------+--------------+--------+--------+---------+---------+--------+---------+---------+--------+----------------+-----------------+------------------+\n",
      "BoxLevelMeanAveragePrecision(iou_type=('bbox',), box_format=xyxy, iou_threshold=0.5:0.95, rec_threshold=0.0:1.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\songj\\AppData\\Local\\Temp\\ipykernel_72544\\1399842326.py:208: UserWarning: Category 'person', ID = 0 not in preds or targets, but in classwise.This information can be ignored if you are sure there is not a problem.\n",
      "  warnings.warn(f\"Category '{cls_name}', ID = {idx} not in preds or targets, but in classwise.\"\n",
      "C:\\Users\\songj\\AppData\\Local\\Temp\\ipykernel_72544\\1399842326.py:208: UserWarning: Category 'cycle', ID = 3 not in preds or targets, but in classwise.This information can be ignored if you are sure there is not a problem.\n",
      "  warnings.warn(f\"Category '{cls_name}', ID = {idx} not in preds or targets, but in classwise.\"\n"
     ]
    }
   ],
   "source": [
    "preds = [\n",
    "   dict(\n",
    "     boxes=tensor([[258.0, 41.0, 606.0, 285.0],\n",
    "                   [158.0, 41.0, 462.0, 285.0]]),\n",
    "     scores=tensor([0.536, 0.71]),\n",
    "     labels=tensor([1, 2]),\n",
    "   ),\n",
    "    dict(\n",
    "     boxes=tensor([[254.0, 413.0, 656.0, 245.0]]),\n",
    "     scores=tensor([0.526]),\n",
    "     labels=tensor([1]),\n",
    "   )\n",
    " ]\n",
    "target = [\n",
    "   dict(\n",
    "     boxes=tensor([[214.0, 41.0, 562.0, 285.0],\n",
    "                   [158.0, 41.0, 462.0, 285.0]]),\n",
    "     labels=tensor([1,2]),\n",
    "   ),\n",
    "       dict(\n",
    "     boxes=tensor([[258.0, 41.0, 606.0, 285.0]]),\n",
    "     labels=tensor([1]),\n",
    "   )\n",
    " ]\n",
    "# metric =MeanAveragePrecision(iou_type=\"bbox\", class_metrics=True)\n",
    "metric =BoxLevelMeanAveragePrecision(iou_type=\"bbox\", class_metrics=True, extended_summary=False, max_detection_thresholds=[1,10,100], classwise={0:'person', 1:'car', 2:'tea', 3:'cycle'})\n",
    "metric.update(target, preds)\n",
    "results=metric.get()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>mAP@0.5:0.95</th>\n",
       "      <th>mAP@50</th>\n",
       "      <th>mAP@75</th>\n",
       "      <th>mAP_s</th>\n",
       "      <th>mAP_m</th>\n",
       "      <th>mAP_l</th>\n",
       "      <th>mAR_s</th>\n",
       "      <th>mAR_m</th>\n",
       "      <th>mAR_l</th>\n",
       "      <th>mAR_max_dets@1</th>\n",
       "      <th>mAR_max_dets@10</th>\n",
       "      <th>mAR_max_dets@100</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>All</td>\n",
       "      <td>0.6515</td>\n",
       "      <td>0.7525</td>\n",
       "      <td>0.7525</td>\n",
       "      <td>-1.0000</td>\n",
       "      <td>-1.0000</td>\n",
       "      <td>0.6515</td>\n",
       "      <td>-1.0000</td>\n",
       "      <td>-1.0000</td>\n",
       "      <td>0.6500</td>\n",
       "      <td>0.6500</td>\n",
       "      <td>0.6500</td>\n",
       "      <td>0.6500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>car</td>\n",
       "      <td>0.3030</td>\n",
       "      <td>0.5050</td>\n",
       "      <td>0.5050</td>\n",
       "      <td>-1.0000</td>\n",
       "      <td>-1.0000</td>\n",
       "      <td>0.3030</td>\n",
       "      <td>-1.0000</td>\n",
       "      <td>-1.0000</td>\n",
       "      <td>0.3000</td>\n",
       "      <td>0.3000</td>\n",
       "      <td>0.3000</td>\n",
       "      <td>0.3000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>tea</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>-1.0000</td>\n",
       "      <td>-1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>-1.0000</td>\n",
       "      <td>-1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  category mAP@0.5:0.95  mAP@50  mAP@75    mAP_s    mAP_m   mAP_l    mAR_s  \\\n",
       "0      All       0.6515  0.7525  0.7525  -1.0000  -1.0000  0.6515  -1.0000   \n",
       "1      car       0.3030  0.5050  0.5050  -1.0000  -1.0000  0.3030  -1.0000   \n",
       "2      tea       1.0000  1.0000  1.0000  -1.0000  -1.0000  1.0000  -1.0000   \n",
       "\n",
       "     mAR_m   mAR_l mAR_max_dets@1 mAR_max_dets@10 mAR_max_dets@100  \n",
       "0  -1.0000  0.6500         0.6500          0.6500           0.6500  \n",
       "1  -1.0000  0.3000         0.3000          0.3000           0.3000  \n",
       "2  -1.0000  1.0000         1.0000          1.0000           1.0000  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metric.table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'classes': tensor([1, 2], dtype=torch.int32),\n",
       " 'ALL': {'map': tensor([0.6515]),\n",
       "  'map_50': tensor([0.7525]),\n",
       "  'map_75': tensor([0.7525]),\n",
       "  'map_small': tensor([-1.]),\n",
       "  'map_medium': tensor([-1.]),\n",
       "  'map_large': tensor([0.6515]),\n",
       "  'mar_1': tensor([0.6500]),\n",
       "  'mar_10': tensor([0.6500]),\n",
       "  'mar_100': tensor([0.6500]),\n",
       "  'mar_small': tensor([-1.]),\n",
       "  'mar_medium': tensor([-1.]),\n",
       "  'mar_large': tensor([0.6500]),\n",
       "  'map_per_class': tensor([0.3030, 1.0000]),\n",
       "  'mar_100_per_class': tensor([0.3000, 1.0000])},\n",
       " 1: {'name': 'car',\n",
       "  'map': tensor(0.3030, dtype=torch.float64),\n",
       "  'map_50': tensor(0.5050, dtype=torch.float64),\n",
       "  'map_75': tensor(0.5050, dtype=torch.float64),\n",
       "  'map_small': tensor([-1]),\n",
       "  'map_medium': tensor([-1]),\n",
       "  'map_large': tensor(0.3030, dtype=torch.float64),\n",
       "  'mar': tensor(0.3000, dtype=torch.float64),\n",
       "  'mar_small': tensor([-1]),\n",
       "  'mar_medium': tensor([-1]),\n",
       "  'mar_large': tensor(0.3000, dtype=torch.float64),\n",
       "  'mar_1': tensor(0.3000, dtype=torch.float64),\n",
       "  'mar_10': tensor(0.3000, dtype=torch.float64),\n",
       "  'mar_100': tensor(0.3000, dtype=torch.float64)},\n",
       " 2: {'name': 'tea',\n",
       "  'map': tensor(1.0000, dtype=torch.float64),\n",
       "  'map_50': tensor(1.0000, dtype=torch.float64),\n",
       "  'map_75': tensor(1.0000, dtype=torch.float64),\n",
       "  'map_small': tensor([-1]),\n",
       "  'map_medium': tensor([-1]),\n",
       "  'map_large': tensor(1.0000, dtype=torch.float64),\n",
       "  'mar': tensor(1., dtype=torch.float64),\n",
       "  'mar_small': tensor([-1]),\n",
       "  'mar_medium': tensor([-1]),\n",
       "  'mar_large': tensor(1., dtype=torch.float64),\n",
       "  'mar_1': tensor(1., dtype=torch.float64),\n",
       "  'mar_10': tensor(1., dtype=torch.float64),\n",
       "  'mar_100': tensor(1., dtype=torch.float64)}}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BoxLevelMeanAveragePrecision.update() took 0.00s each time.\n",
      "+----------+--------------+--------+--------+--------+---------+---------+--------+---------+---------+----------------+-----------------+------------------+\n",
      "| category | mAP@0.5:0.95 | mAP@50 | mAP@75 | mAP_s  |  mAP_m  |  mAP_l  | mAR_s  |  mAR_m  |  mAR_l  | mAR_max_dets@1 | mAR_max_dets@10 | mAR_max_dets@100 |\n",
      "+----------+--------------+--------+--------+--------+---------+---------+--------+---------+---------+----------------+-----------------+------------------+\n",
      "|   All    |    0.2000    | 1.0000 | 0.0000 | 0.2000 | -1.0000 | -1.0000 | 0.2000 | -1.0000 | -1.0000 |     0.2000     |      0.2000     |      0.2000      |\n",
      "|    0     |    0.2000    | 1.0000 | 0.0000 | 0.2000 | -1.0000 | -1.0000 | 0.2000 | -1.0000 | -1.0000 |     0.2000     |      0.2000     |      0.2000      |\n",
      "+----------+--------------+--------+--------+--------+---------+---------+--------+---------+---------+----------------+-----------------+------------------+\n",
      "BoxLevelMeanAveragePrecision(iou_type=('segm',), box_format=xyxy, iou_threshold=0.5:0.95, rec_threshold=0.0:1.0)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'classes': tensor([0], dtype=torch.int32),\n",
       " 'ALL': {'map': tensor([0.2000]),\n",
       "  'map_50': tensor([1.]),\n",
       "  'map_75': tensor([0.]),\n",
       "  'map_small': tensor([0.2000]),\n",
       "  'map_medium': tensor([-1.]),\n",
       "  'map_large': tensor([-1.]),\n",
       "  'mar_1': tensor([0.2000]),\n",
       "  'mar_10': tensor([0.2000]),\n",
       "  'mar_100': tensor([0.2000]),\n",
       "  'mar_small': tensor([0.2000]),\n",
       "  'mar_medium': tensor([-1.]),\n",
       "  'mar_large': tensor([-1.]),\n",
       "  'map_per_class': tensor([-1.]),\n",
       "  'mar_100_per_class': tensor([-1.])},\n",
       " 0: {'name': '0',\n",
       "  'map': tensor(0.2000, dtype=torch.float64),\n",
       "  'map_50': tensor(1.0000, dtype=torch.float64),\n",
       "  'map_75': tensor(0., dtype=torch.float64),\n",
       "  'map_small': tensor(0.2000, dtype=torch.float64),\n",
       "  'map_medium': tensor([-1]),\n",
       "  'map_large': tensor([-1]),\n",
       "  'mar': tensor(0.2000, dtype=torch.float64),\n",
       "  'mar_small': tensor(0.2000, dtype=torch.float64),\n",
       "  'mar_medium': tensor([-1]),\n",
       "  'mar_large': tensor([-1]),\n",
       "  'mar_1': tensor(0.2000, dtype=torch.float64),\n",
       "  'mar_10': tensor(0.2000, dtype=torch.float64),\n",
       "  'mar_100': tensor(0.2000, dtype=torch.float64)}}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch import tensor\n",
    "from torchmetrics.detection import MeanAveragePrecision\n",
    "mask_pred = [\n",
    "   [0, 0, 0, 0, 0],\n",
    "   [0, 0, 1, 1, 0],\n",
    "   [0, 0, 1, 1, 0],\n",
    "   [0, 0, 0, 0, 0],\n",
    "   [0, 0, 0, 0, 0],\n",
    " ]\n",
    "mask_tgt = [\n",
    "   [0, 0, 0, 0, 0],\n",
    "   [0, 0, 1, 0, 0],\n",
    "   [0, 0, 1, 1, 0],\n",
    "   [0, 0, 1, 0, 0],\n",
    "   [0, 0, 0, 0, 0],\n",
    " ]\n",
    "preds = [\n",
    "   dict(\n",
    "     masks=tensor([mask_pred], dtype=torch.bool),\n",
    "     scores=tensor([0.536]),\n",
    "     labels=tensor([0]),\n",
    "   )\n",
    " ]\n",
    "target = [\n",
    "   dict(\n",
    "     masks=tensor([mask_tgt], dtype=torch.bool),\n",
    "     labels=tensor([0]),\n",
    "   )\n",
    " ]\n",
    "metric = BoxLevelMeanAveragePrecision(iou_type=\"segm\")\n",
    "metric.update(target, preds)\n",
    "metric.get()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sos",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
